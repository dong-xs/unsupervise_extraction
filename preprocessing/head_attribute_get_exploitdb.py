# encoding:utf-8
'''
    该py文件的目的是构建spacy分句后每一文本块中，所有的特殊属性抬头，
    如：Vendor、Version、Product等
    将这些特殊属性抬头构建成为一个字典集合
'''

# 查看文本数据格式
import chardet
# f=open('../data/DongPaper_cve_hyperlink_info_exploitdb.csv')
# data=f.read()
# print(chardet.detect(data))

import pandas as pd

content = pd.read_csv('../data/DongPaper_cve_hyperlink_info.csv', encoding='utf-8')  # 读取文件时，一个点表示跳到上一级
exploit = content['exploit_db_info'].values.tolist()

# 还存在一个问题，就是一个exploitdb中可能存在两个站点，暂不处理，暂时只取每个字典的第一个key-value值
new_exploit = [list(eval(i)[0].values())[0] for i in exploit if len(eval(i)) != 0]  # 每一个exploit的url对应的文本内容，格式为str

import spacy

nlp = spacy.load('en_core_web_md')
nlp.max_length = 1500000  # 设置spacy可处理的字符长度，默认为1000000


def explotit_db_sentence_recongnization(txt):
    '''

    :param txt: 一个漏洞报告文本
    :return: 每个句子文本中包含的所有句子
    '''
    assert len(txt) < 1500000
    doc = nlp(txt)
    value = []  # 用于存放spacy识别出的各个分句结果
    for sent in doc.sents:
        value.append(str(sent))

    final_attrs = []

    for item in value:  # 是否可以考虑先只处理出现在前两个分句结果里的内容，也可处理所有的分句
        final_attrs.extend(detail_sentence_recongnization(item))  # 先以第一个文本的第一个分句结果为例，实际上，每个分句中都有可能包含属性值
    return final_attrs



def detail_sentence_recongnization(spacy_sent_text):
    '''

    :param spacy_sent_text: 使用spacy分句后的结果
    :return: 这个分句文本内的属性头
    '''
    tag_count = spacy_sent_text.count('\r\n')  # 由于每个句子的结果都是\r\n，即\r\n可以考虑为一个分割符
    content = spacy_sent_text.split('\r\n', tag_count)

    content = [value for value in content if value != '#' and len(value.strip()) != 0 and value != '-']  # 去掉空行和仅包含“#”的行

    attrs = []

    for item in content:
        item = item.replace('\t', '').strip()  # 有些句子前面以\t开头，这些内容可以直接替换为空
        split_result = item.split(":")
        if len(split_result) > 1:  # 如果一个列表中包含了“：”
            if split_result[0].startswith("#") or split_result[0].startswith("//"):  # 如果一个属性头是以“#”或“//”开头，那么要将这个“#”或“//”去掉才行
                attrs.append(split_result[0].split(' ',1)[-1].strip())    #每一个“#”或“//”开头的内容都将会有一个空格

            elif split_result[0] == '':  # 存在以“：”开头的情况
                pass
            else:  # 与些同时也会有不是以“#”开头的，这种情况则直接追加到目标列表中即可
                attrs.append(split_result[0])
        else:
            continue

    attrs = [value for value in attrs if
             value is not None and value != '' and value[0].isupper()]  # 如果一个属性头部是以小写字母开头，那么其必定不是属性

    return attrs


all_attrs = []

for txt in new_exploit:
    all_attrs.extend(explotit_db_sentence_recongnization(txt))

all_attrs = [value.strip() for value in all_attrs]

from collections import Counter

static_value = Counter(all_attrs)  # 统计每个域名出现的次数
sorted_value = sorted(static_value.items(), key=lambda x: x[1], reverse=True)  # 按统计次数逆序排列

with open('..\data\exploit_head_attributes.txt', 'w', encoding='utf-8') as f:
    for values in sorted_value:
        f.write(str(values) + '\n')
f.close()

print('write success!')

'''
    按照当前生成的属性头部形式，最后共产生了13982个不同的头部
    通过观察，我们仅保留了
'''
